# üìò Learning: Docker Disk Space Management & Troubleshooting

**Szenario:** Deployment schl√§gt fehl (`rsync error: No space left on device`) oder der Server reagiert tr√§ge, weil die Festplatte voll ist.

---

## 1. üîç Analyse: Wo ist der Speicherplatz hin?

Bevor du blind l√∂schst, finde heraus, was den Platz verbraucht.

### Schritt 1.1: Gesamtspeicher pr√ºfen
Verschaffe dir einen √úberblick √ºber die Partitionen.
```bash
df -h
```
*   Achte auf die Spalte `Use%` bei `/` (Root). Wenn hier 90-100% steht, ist die Platte voll.

### Schritt 1.2: Die gr√∂√üten Verzeichnisse finden
Finde heraus, welcher Ordner der √úbelt√§ter ist.
```bash
sudo du -h /var | sort -rh | head -n 10
```
*   **Ergebnis-Interpretation:**
    *   `/var/lib/docker`: Docker Images, Container & Volumes (meistens das Problem).
    *   `/var/log`: System-Logs (k√∂nnen bei Fehlern explodieren).

---

## 2. üê≥ Ursache: Docker (Der h√§ufigste Grund)

Docker beh√§lt standardm√§√üig **alles**: alte Images nach Updates, gestoppte Container, Build-Caches und nicht genutzte Volumes.

### Schritt 2.1: Docker aufr√§umen (Die "Atombombe")
Dieser Befehl l√∂scht alles, was nicht *aktiv* von einem *laufenden* Container verwendet wird.
**‚ö†Ô∏è Achtung:** L√∂scht auch Volumes, die nicht gemountet sind!

```bash
sudo docker system prune -af --volumes
```
*   `-a`: L√∂scht alle ungenutzten Images (nicht nur "dangling").
*   `-f`: Force (keine R√ºckfrage).
*   `--volumes`: L√∂scht auch ungenutzte Volumes.

### Schritt 2.2: Docker Logs leeren (ohne Container-Neustart)
Manchmal schreibt ein Container (z.B. Streamlit im Loop) Gigabytes an Logs.
```bash
sudo sh -c 'truncate -s 0 /var/lib/docker/containers/*/*-json.log'
```

---

## 3. üìú Ursache: System Logs

Wenn eine App crasht und neustartet (Crash-Loop), k√∂nnen Logs wie `syslog` oder `journal` riesig werden.

### Schritt 3.1: Journald aufr√§umen
```bash
# Behalte nur die Logs der letzten Sekunde (l√∂scht alles Alte)
sudo journalctl --vacuum-time=1s

# Oder: Begrenze auf eine feste Gr√∂√üe
sudo journalctl --vacuum-size=100M
```

---

## 4. üõ†Ô∏è Pr√§vention & Automatisierung

Damit das nicht wieder passiert, baue Sicherheitsnetze ein.

### Schritt 4.1: GitHub Actions (Deployment)
F√ºge vor dem `rsync` oder Build-Schritt einen Cleanup-Befehl ein, um Platz f√ºr das neue Deployment zu schaffen.

```yaml
- name: Pre-cleanup on server
  run: |
    ssh user@host "sudo docker system prune -af --volumes || true"
```

### Schritt 4.2: Docker Logging begrenzen (`docker-compose.yml`)
Verhindere, dass Container-Logs unendlich wachsen. F√ºge dies zu jedem Service hinzu:

```yaml
logging:
  driver: "json-file"
  options:
    max-size: "10m"
    max-file: "3"
```

### Schritt 4.3: Cronjob (Optional)
Ein t√§glicher Cronjob auf dem Server, der aufr√§umt:
```bash
# crontab -e
0 4 * * * docker system prune -af --volumes > /dev/null 2>&1
```
*(L√∂scht jeden Tag um 04:00 Uhr alles Unn√∂tige)*

---

## ‚ö° Schnell-Checkliste f√ºr den Notfall

Wenn nichts mehr geht, kopiere diesen Block und f√ºhre ihn auf dem Server aus:

```bash
# 1. Docker komplett aufr√§umen
sudo docker system prune -af --volumes

# 2. Docker Logs leeren
sudo sh -c 'truncate -s 0 /var/lib/docker/containers/*/*-json.log'

# 3. System Logs leeren
sudo journalctl --vacuum-time=1s

# 4. Apt Cache leeren
sudo apt-get clean

# 5. Ergebnis pr√ºfen
df -h
```
